# Адаптивный алгоритм управления статическим объектом

## Постановка задачи
Рассматривается постановка задачи управления многомерным статическим объектом в условиях неопределенности с некоторой исходной обучающей выборкой и активным накоплением информации (через заданное значение ∆t), т.е. выборка пополняемая. Сведения о виде зависимости между входными и выходными переменными отсутствует. Имеется лишь информация о характере входных выходных переменных, например, какие входы являются управляемыми, а какие неуправляемыми, но измеряемыми и  т.д. В ходе функционирования объект управления может менять свои состояния (переходить из одного режима функционирования в другой).
Описываемый алгоритм относиться к классу адаптивных в силу его возможностей перенастраиваться к изменяющимся условиям (в том, числе внешним).

![Модель системы](/images/model_of_system.jpg)


## Метод решения
Для нахождения следующего значения управляемых переменных воспользуемся последовательным алгоритмом управления на остнове непараметрической оценки регрессии:

$$u^j_{s+1} = \frac{\sum_{i=1}^{s} u_j[i]\LargeФ(\frac{x^*-x_i}{c_s^x})\LargeФ(\frac{\mu^*-x_i}{c_s^\mu})}
{\sum_{i=1}^{s}\LargeФ(\frac{x^*-x_i}{c_s^x})\LargeФ(\frac{\mu^*-x_i}{c_s^\mu})}$$

Кроме того необходимо использовать усиление регулятора

$u(t) = Kp * e(t)$,

где:

- $u(t)$ — управляющее воздействие;

- $Kp$ — коэффициент усиления регулятора;

- $e(t)$ — ошибка регулирования.


$e(t)=x_{зад}(t)-x(t)$,

где:

- $x_{зад}$ — заданное значение регулируемой величины,
- $x$ — текущее значение регулируемой величины (предыдущее).

При использовании регулятора необходимо учесть, что если коэффициент будет слишком большой, то можно $u(t)$ может попасть за границы обучающей выборки. Кроме того желаемое $x(\vec{u},\vec{\mu})$ также может быть за границами выборки.

Для этого был использован алгоритм предотвращения выхода желаемого значения за пределы, которые достигаемы непараметрической оценкой.
```python
def find_borders(train, dot, blur):
    k = 0.2
    maxi = train[ np.argmax(train) ]
    mini = train[ np.argmin(train) ]
    if dot > ( maxi + k*blur): return maxi + (k*0.5)*blur
    elif dot < ( mini + k*blur): return mini - (k*0.5)*blur
    else: return dot
```

Таким образом, желаемое значение, полученное использованием данной функции, шаг за шагом приближается к заданному значению.

Это решение помогает избежать точек, находящихся за границами обучающей выборки, но не позволяет избежать тех, что находятся в разреженных местах.
В основе решения этой проблемы лежит обрезание выборки - в результирующую выбрку попадают только те примеры, что находятся от последней точки не дальше чем $k_s*C_s^i$. Это обеспечивает не только решение проблемы, но и использование в обучающей выборке только ближайших точек, что совместно с предыдущим алгоритмом обеспечивает плавный переход от одного состояния к другому.
```python
def catch_train_sample(train,X,par_blur):
    k = 1
    mask = (train > (X-k*par_blur)) & (train < (X+k*par_blur))
    sample = train[mask]
    return sample
```
## Проведение эксперимента

В качестве функции для генерации обучающей выборки использованы следующие методы
```python
def datasets_make_regression(func, count_dots, random_state, dispersion, border):

    np.random.seed(random_state)
    x1 = np.linspace(border[0,0], border[0,1], count_dots)
    u1 = np.sin(x1*0.5) + np.random.normal(0,dispersion,len(x1))

    x2 = np.linspace(border[1,0], border[1,1], count_dots)
    u2 = np.power(x2, 1/2) + np.random.normal(0,dispersion,len(x2))
    #u2 = x2 + np.random.normal(0,dispersion,len(x2))

    x3 = np.linspace(border[2,0], border[2,1], count_dots)
    m1 = np.cos(0.3 * x3) + np.random.normal(0,dispersion,len(x3))

    y = func(u1,u2,m1) + np.random.normal(0,dispersion,len(x3))

    return u1, u2, m1, y
```
Сам объект представлен выражением

$$x(\vec{u},\vec{\mu}) = 0.8 * u_2 + 0.4 * u_1 + 0.05 * m_1$$

Обучающая выборка содержит в себе 1000 примеров.
![Обучающая выборка](/images/train.png)

### Выходное значение в виде функции косинуса


При управлении объектом получены следующие результаты

![Управление при ступенчатом воздействии](/images/cos.png)

Ошибка MSE при управлении составила  0.0007

Зелёным отображено значение желаемого X, полученного в результате выполнения функции find_borders.
На графике видны периодические вплески. Во время их возникновения происходит значимое обновление обучающей выборки.

### Выходное значение в виде ступенчатой функции

Генерация заданного ступенчатого выхода производилась по следующему выражению:
$$x(t) = 
\begin{equation}
    \begin{cases}
      -5, t<200\\
      10, t<400\\
      7, t<600\\
      5.5, t\ge600\\
    \end{cases}\,.
\end{equation}$$


При управлении объектом получены следующие результаты

![Управление при ступенчатом воздействии](/images/hevi.png)

Ошибка MSE при управлении составила  0.641

Из графика видно четкую работу методов по обрезке обучающей выборки и плавного перехода переменной в области, где обучающая выборка не представлена.